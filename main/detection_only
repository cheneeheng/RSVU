#!/usr/bin/env python3

# -----------------------------------------------------------------------------
# Demo agent for passive mode that steps through each of the available poses in
# the environment, executing the "move_next" action recursively. Observations
# are visualised by the agent at the completion of each action.

# from benchbot_api import BenchBot
# from guided_agent import GuidedAgent
# if __name__ == '__main__':
#     BenchBot(agent=GuidedAgent()).run()

# ------------------------------------------------------------------------------

import os
import numpy as np
from PIL import Image, ImageDraw
from benchbot_api import ActionResult, Agent, BenchBot
from votenet_benchbot import votenet_build, votenet_detection  # new imports!

import time
import torch
import torchvision
import json
import cv2
import random

import detectron2
from detectron2.utils.logger import setup_logger
setup_logger()

from detectron2 import model_zoo
from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2.utils.visualizer import Visualizer
from detectron2.data import MetadataCatalog, DatasetCatalog

from utils import load_yaml_list


class MyAgent(Agent):
    def __init__(self):
        self._votenet = votenet_build()
        self._frame_idx = 0
        self.cfg = get_cfg()
        coco_cfg_file = model_zoo.get_config_file(
            "COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml")
        self.cfg.merge_from_file(coco_cfg_file)
        self.cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5
        self.cfg.MODEL.WEIGHTS = "/pretrained_models/model_final_f10217.pkl"
        self.predictor = DefaultPredictor(self.cfg)
        # print(f"Image mode : {cfg.INPUT.FORMAT}")

    def is_done(self, action_result):
        return action_result != ActionResult.SUCCESS

    def pick_action(self, observations, action_list):

        # ----------------------------------------------------------------------
        # 1. Votenet Detection

        # print(f"Obs Cam : {observations['image_depth_info']}")
        # print(f"Obs Dep : {observations['image_rgb_info']}")
        # print(f"Obs Pos : {observations['poses']}")
        results = votenet_detection(self._votenet, observations)
        print(f"Detected {len(results)} objects in the frame.")
        print(f"Class: {[r['class'] for r in results]}")
        # print(f"Centroid: {[r['centroid'] for r in results]}")
        # print(f"Centroid camera: {[r['centroid_camera'] for r in results]}")
        # print(f"Boxcorners camera: {[r['box_corners_camera'] for r in results]}")

        if len(results) > 0:
            im = Image.fromarray(observations['image_rgb'])
            draw = ImageDraw.Draw(im, "RGBA")
            for r in results:
                cent = r['centroid_camera']
                exte = r['extent_camera']
                f = np.array([480], dtype=np.float32)
                cx = observations['image_rgb'].shape[1] / 2.0
                cy = observations['image_rgb'].shape[0] / 2.0
                x1 = (((cent[0] - (exte[0]/2)) * f) / cent[2]) + cx
                y1 = (((cent[1] - (exte[1]/2)) * f) / cent[2]) + cy
                x2 = (((cent[0] + (exte[0]/2)) * f) / cent[2]) + cx
                y2 = (((cent[1] + (exte[1]/2)) * f) / cent[2]) + cy
                draw.rectangle((x1, y1, x2, y2),
                               fill=(0, 0, 0, 0),
                               outline=(255, 0, 0, 255))
                draw.text((x1, y1), r['class'], (255, 0, 0, 255))
            im.save(f'/results/img{self._frame_idx}.png')

        # ----------------------------------------------------------------------
        # 2. MRCNN Detection

        tic = time.time()
        outputs = self.predictor(observations['image_rgb'][:, :, ::-1])
        toc = time.time()
        print('Inference time MRCNN: %f' % (toc - tic))
        
        v = Visualizer(observations['image_rgb'],
                       MetadataCatalog.get(self.cfg.DATASETS.TRAIN[0]),
                       scale=1.2)
        out = v.draw_instance_predictions(outputs["instances"].to("cpu"))
        d2_im = Image.fromarray(out.get_image())
        d2_im.save(f'/results/d2_img{self._frame_idx}.png')

        self._frame_idx += 1
        return 'move_next', {}

    def save_result(self, filename, empty_results, results_formant_fns):
        pass  # No results to save yet


if __name__ == '__main__':
    print("Welcome to my Semantic SLAM solution!")

    gt_data = load_yaml_list([os.path.join('/ground_truths', i)
                              for i in sorted(os.listdir('/ground_truths'))])

    print("END")

    BenchBot(agent=MyAgent()).run()
